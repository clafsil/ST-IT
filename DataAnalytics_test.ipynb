{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "DataAnalytics_test.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eec3119"
      },
      "source": [
        "# ST IT Cloud - Data and Analytics Test LV.4\n",
        "\n",
        "Esse teste deve avaliar alguns conceitos de big data e a qualidade técnica na manipulacão de dados, otimização de performance, trabalho com arquivos grandes e tratamento de qualidade.\n",
        "\n",
        "## Passo a passo\n",
        "\n",
        "- *Parte teórica:* responda as questões abaixo preenchendo as células em branco.\n",
        "- *Parte prática:* disponibilizamos aqui 2 cases para, leia os enunciados dos problemas, desenvolver os programas, utilizando a **stack definida durante o processo seletivo**, para entregar os dados de acordo com os requisitos descritos abaixo.\n",
        "\n",
        "\n",
        "\n",
        "**Faz parte dos critérios de avaliacão a pontualidade da entrega. Implemente até onde for possível dentro do prazo acordado.**\n",
        "\n",
        "**Os dados de pessoas foram gerados de forma aleatória, utilizando a biblioteca FakerJS, FakerJS-BR e Faker**\n",
        "\n",
        "LEMBRE-SE: A entrega deve conter TODOS os passos para o avaliador executar o programa (keep it simple).\n"
      ],
      "id": "9eec3119"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9447dec4"
      },
      "source": [
        "**Questão 1** - Descreva de forma detalhada quais são as etapas na construção de um pipeline de dados, sem considerar ferramentas específicas, imagine que é seu primeiro contato com o cliente e você precisa entender a demanda dele e explicar quais são os passos que você terá que implementar para entregar a demanda."
      ],
      "id": "9447dec4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c11c64a8"
      },
      "source": [
        "# Resposta: O primeiro passo é entender a demanda fazendo o levantamento dos requisitos. Conhecendo o problema, \n",
        "# teremos condições de realizar o desenho da soluçao técnica e planejar o desenvolvimento, homologar e implantar a demanda.\n",
        "\n",
        "# A construção do pipeline de dados abrange as seguintes etapas: mapeamento dos dados na origem, ingestão do dado bruto no destino (exemplo: camada row data no data lake),\n",
        "# particionamento (exemplo: parquet), transformação dos dados aplicando as regras de negócio, padronização e limpeza (exemplo:  EMR) e disponibilização da informação em um DW (exemplo: Redshift)\n",
        "\n"
      ],
      "id": "c11c64a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc703af3"
      },
      "source": [
        "**Questão 2** - Defina com suas palavras um processamento em streaming e processamento em batch. Qual sua experiência com cada uma delas."
      ],
      "id": "dc703af3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "028a8db5"
      },
      "source": [
        "# O processamento em streaming deve ser continuo, pois existe a necessidade de utilizar os dados em tempo real para gerar valor ao negócio. Por exemplo, o cliente ao efetivar uma compra ele já recebe uma pesquisa de satisfação em seu e-mail.\n",
        "# O processamento em batch pode ter uma janela de processamento programada. Um exemplo para esse modelo são os paineis de indicadores executivos, onde não há necessidade de acompanhando em tempo real. \n"
      ],
      "id": "028a8db5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c1c3f10"
      },
      "source": [
        "**Questão 3** - Quais são as camadas de um Data Lake?"
      ],
      "id": "1c1c3f10"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b803419"
      },
      "source": [
        "# As camadas são: \n",
        "#    1.Row Data - Armazenamento de dados Brutos \n",
        "#    2.Trusted  - Camada onde os dados são desnormalizados e centralizados, aplicando rotinas para limpar, padronizar e definir nomenclaturas amigáveis dos campos.\n",
        "#    3.Refined  - Camada onde os dados são transformados ou enriquecidos de acordo a regra do negócio"
      ],
      "id": "5b803419",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62477089"
      },
      "source": [
        "**Questão 4** - Quais as diferenças de um Data Lake e um DW?"
      ],
      "id": "62477089"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86c408c7"
      },
      "source": [
        "# O Data Lake armazena dados estruturados, semi-estruturados e nao estruturados, que pode vir de diversas fontes (sistemas legados, dados abertos, imagens, redes sociais etc)\n",
        "# O DW armazena os dados transformados e estruturados e estão prontos para responder as necessidades do négocio."
      ],
      "id": "86c408c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7099a05e"
      },
      "source": [
        "**Questão 5** - O que é arquitetura Lambda e Kappa? Descreva com suas palavras."
      ],
      "id": "7099a05e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4347923"
      },
      "source": [
        "# Arquitetura Lambda consiste em processar o dado em lote e disponibilizar para uso. Já a arquitetura Kappa não tem a camada de lote, sendo assim o processamento é contínuo."
      ],
      "id": "b4347923",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e3d483e"
      },
      "source": [
        "**Questão 6** - O que é Data Quality para você e como você implementa isso nos seus processos?"
      ],
      "id": "6e3d483e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf54dfa9"
      },
      "source": [
        ""
      ],
      "id": "bf54dfa9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd4834d6"
      },
      "source": [
        "**Questão 7** - Em uma escala de 0 a 10, qual seria seu nível de experiência com PySpark?"
      ],
      "id": "bd4834d6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86ddda4b"
      },
      "source": [
        "4"
      ],
      "id": "86ddda4b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66ef78ba"
      },
      "source": [
        "**Questão 8** - Em uma escala de 0 a 10, qual seria seu nível de experiência com SQL?"
      ],
      "id": "66ef78ba"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33569bd8"
      },
      "source": [
        "10"
      ],
      "id": "33569bd8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e5f7ee6"
      },
      "source": [
        "**Questão 9** - Descreva suas expeciências com banco de dados SQL e NoSQL."
      ],
      "id": "5e5f7ee6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a558d57a"
      },
      "source": [
        "# SQL: Trabalho com SQL (T-SQL e Oracle) em toda a minha trajetória profissional, desenvolvendo procedures e querys. Já os banco não relacionais, atuo a 2 anos no DymanoDB e fiz alguns trabalhos acadêmicos utilizando o Neo4j."
      ],
      "id": "a558d57a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef2fa6e5"
      },
      "source": [
        "**Questão 10** - Tem experiência com versionamento de código? Com quais ferramentas já trabalhou? Descreva."
      ],
      "id": "ef2fa6e5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1932a1b0"
      },
      "source": [
        "# Sim, recentemente utilizo o Git. Porém já trabalhei com o TFS (Team Foundation Service) "
      ],
      "id": "1932a1b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efe2714f"
      },
      "source": [
        "**Questão 11** - Tem experiência em desenvolvimento em cloud? Se sim, especifique a(s) plataforma(s) que já trabalhou e suas principais implementações e conhecimentos em cada serviço."
      ],
      "id": "efe2714f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d47d2a32"
      },
      "source": [
        "# Sim, tenho dois anos de experiencia em desenvolvimento nos serviços da AWS.\n",
        "# São eles: EMR, Lambda e Step Function."
      ],
      "id": "d47d2a32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af9bc70d"
      },
      "source": [
        "**Questão 12** - Tem experiência com metodologia ágil? Qual?"
      ],
      "id": "af9bc70d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c5be8d7"
      },
      "source": [
        "# Sim, Scrum."
      ],
      "id": "7c5be8d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXASkdZ2Droa"
      },
      "source": [
        "# instalar as dependências\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "id": "OXASkdZ2Droa",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b1b6c2d"
      },
      "source": [
        "# configurar as variáveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "\n",
        "# tornar o pyspark \"importável\"\n",
        "import findspark\n",
        "findspark.init('spark-2.4.4-bin-hadoop2.7')\n",
        "\n"
      ],
      "id": "3b1b6c2d",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z89F1yTKA7dO"
      },
      "source": [
        "from pyspark.sql import SparkSession, types\n",
        "from pyspark.sql import Window, DataFrame, functions\n",
        "from pyspark.sql.functions import *\n",
        "\n"
      ],
      "id": "Z89F1yTKA7dO",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eb61f06"
      },
      "source": [
        "# TESTE PRÁTICO"
      ],
      "id": "1eb61f06"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ed8c6a5"
      },
      "source": [
        "**Problema 1**: Você está recebendo o arquivo 'dados_cadastrais_fake.csv' que contem dados cadastrais de clientes, mas para que análises ou relatórios sejam feitos é necessário limpar e normalizar os dados. Além disso, existe uma coluna com o número de cpf e outra com cnpj, você precisará padronizar deixando apenas dígitos em formato string (sem caracteres especiais), implementar uma forma de verificar se tais documentos são válidos sendo que a informação deve se adicionada ao dataframe em outras duas novas colunas.\n",
        "\n",
        "Após a normalização, gere reports que respondam as seguintes perguntas:\n",
        "- Quantos clientes temos nessa base?\n",
        "- Qual a média de idade dos clientes?\n",
        "- Quantos clientes nessa base pertencem a cada estado?\n",
        "- Quantos CPFs válidos e inválidos foram encontrados?\n",
        "- Quantos CNPJs válidos e inválidos foram encontrados?\n",
        "\n",
        "Ao final gere um arquivo no formato csv e um outro arquivo no formato parquet chamado (problema1_normalizado), eles serão destinados para pessoas distintas.\n",
        "\n",
        "*EXTRA:* executar as mesmas validações no *1E8.csv.gz"
      ],
      "id": "8ed8c6a5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-kX9AMPEUEh"
      },
      "source": [
        "#ler arquivo\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Spark-Ingest-dados_cadastrais\").getOrCreate()\n",
        "\n",
        "\n",
        "df_dados_cadastrais = spark.read.csv (\"/content/drive/MyDrive/dados_cadastrais_fake.csv\",header=True,sep =';') \n",
        "\n",
        "\n"
      ],
      "id": "b-kX9AMPEUEh",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjllDSh5G-cS",
        "outputId": "b6339ddd-cfe8-4d3e-de08-b325db956518",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#df_dados_cadastrais.count()\n",
        "df_dados_cadastrais.select('*').show()\n",
        " "
      ],
      "id": "cjllDSh5G-cS",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----+-------------------+----------------+--------------+------------------+\n",
            "|             nomes|idade|             cidade|          estado|           cpf|              cnpj|\n",
            "+------------------+-----+-------------------+----------------+--------------+------------------+\n",
            "|    Dennis Daniels|   31|         ACRELÂNDIA|              AC|   97566536800|    06589184909526|\n",
            "|       Leah Becker|   42|        ÁGUA BRANCA|              AL|425.263.807-07|25.673.336/2350-20|\n",
            "|        Sally Ford|   18|           ALVARÃES|              AM|   34647754103|    26543101702989|\n",
            "|    Colleen Duncan|   21|     SERRA DO NAVIO|              AP|252.531.560-03|19.062.080/5100-98|\n",
            "|   Jeff Stephenson|   73|             ABAÍRA|              BA|   49668886542|    97794530015384|\n",
            "|     Sydney Curtis|   85|            ABAIARA|              CE|506.202.907-49|29.476.298/0856-78|\n",
            "|    Kelly Matthews|   44|           Brasília|distrito federal|   39154836808|    24709301957761|\n",
            "|         Juan Ruiz|   39|     AFONSO CLÁUDIO|              ES|226.881.196-48|02.420.338/1479-00|\n",
            "|      Brian Thomas|   26|    ABADIA DE GOIÁS|              GO|   47475484084|    70723419110335|\n",
            "|        Sara Ayers|   62|         AÇAILÂNDIA|              MA|948.309.788-64|88.253.689/5483-82|\n",
            "|        Brady Cruz|   83|ABADIA DOS DOURADOS|              MG|   03438452456|    13118105069639|\n",
            "|   Samantha Wright|   32|         ÁGUA CLARA|              MS|222.036.540-90|04.310.317/3202-52|\n",
            "|    Richard Turner|   85|           ACORIZAL|              MT|   79059712285|    75595541223248|\n",
            "|    Ashley Sanders|   73|         ABAETETUBA|              PA|752.065.139-89|06.923.815/1651-28|\n",
            "|      Thomas Jones|   45|        ÁGUA BRANCA|              PB|   34565179806|    26574533273304|\n",
            "|        Ian Murray|   68|       ABREU E LIMA|              PE|152.777.170-99|85.202.887/3688-51|\n",
            "|     Janice Jensen|   79|              ACAUÃ|              PI|   45081993646|    89596067898809|\n",
            "|Jeffrey Cunningham|   48|             ABATIÁ|              PR|665.490.288-25|18.866.688/3442-42|\n",
            "|      Amanda Glass|   49|     ANGRA DOS REIS|              RJ|   86173803577|    87380936406714|\n",
            "|   Kaitlyn Johnson|   65|              ACARI|              RN|897.370.042-13|40.893.546/7414-94|\n",
            "+------------------+-----+-------------------+----------------+--------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0mVFmRVFwX_"
      },
      "source": [
        "\n",
        "\n",
        "df = df_dados_cadastrais.withColumn('cpf',regexp_replace('cpf', '-',''))\n",
        "  \n",
        "\n",
        "#df.withColumn('address', regexp_replace('address', 'Rd', 'Road')) \\  .show(truncate=False)\n",
        "\n"
      ],
      "id": "y0mVFmRVFwX_",
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N13VfEjwS5Xf",
        "outputId": "120f0711-799e-4506-b997-2a991acf93af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.select('*').show()"
      ],
      "id": "N13VfEjwS5Xf",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----+-------------------+----------------+-------------+------------------+\n",
            "|             nomes|idade|             cidade|          estado|          cpf|              cnpj|\n",
            "+------------------+-----+-------------------+----------------+-------------+------------------+\n",
            "|    Dennis Daniels|   31|         ACRELÂNDIA|              AC|  97566536800|    06589184909526|\n",
            "|       Leah Becker|   42|        ÁGUA BRANCA|              AL|425.263.80707|25.673.336/2350-20|\n",
            "|        Sally Ford|   18|           ALVARÃES|              AM|  34647754103|    26543101702989|\n",
            "|    Colleen Duncan|   21|     SERRA DO NAVIO|              AP|252.531.56003|19.062.080/5100-98|\n",
            "|   Jeff Stephenson|   73|             ABAÍRA|              BA|  49668886542|    97794530015384|\n",
            "|     Sydney Curtis|   85|            ABAIARA|              CE|506.202.90749|29.476.298/0856-78|\n",
            "|    Kelly Matthews|   44|           Brasília|distrito federal|  39154836808|    24709301957761|\n",
            "|         Juan Ruiz|   39|     AFONSO CLÁUDIO|              ES|226.881.19648|02.420.338/1479-00|\n",
            "|      Brian Thomas|   26|    ABADIA DE GOIÁS|              GO|  47475484084|    70723419110335|\n",
            "|        Sara Ayers|   62|         AÇAILÂNDIA|              MA|948.309.78864|88.253.689/5483-82|\n",
            "|        Brady Cruz|   83|ABADIA DOS DOURADOS|              MG|  03438452456|    13118105069639|\n",
            "|   Samantha Wright|   32|         ÁGUA CLARA|              MS|222.036.54090|04.310.317/3202-52|\n",
            "|    Richard Turner|   85|           ACORIZAL|              MT|  79059712285|    75595541223248|\n",
            "|    Ashley Sanders|   73|         ABAETETUBA|              PA|752.065.13989|06.923.815/1651-28|\n",
            "|      Thomas Jones|   45|        ÁGUA BRANCA|              PB|  34565179806|    26574533273304|\n",
            "|        Ian Murray|   68|       ABREU E LIMA|              PE|152.777.17099|85.202.887/3688-51|\n",
            "|     Janice Jensen|   79|              ACAUÃ|              PI|  45081993646|    89596067898809|\n",
            "|Jeffrey Cunningham|   48|             ABATIÁ|              PR|665.490.28825|18.866.688/3442-42|\n",
            "|      Amanda Glass|   49|     ANGRA DOS REIS|              RJ|  86173803577|    87380936406714|\n",
            "|   Kaitlyn Johnson|   65|              ACARI|              RN|897.370.04213|40.893.546/7414-94|\n",
            "+------------------+-----+-------------------+----------------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0UpsafXFZxk"
      },
      "source": [
        ""
      ],
      "id": "S0UpsafXFZxk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2da9c40"
      },
      "source": [
        "**Problema 2**: Você deverá implementar um programa, para ler, tratar e particionar os dados.\n",
        "\n",
        "O arquivo fonte está disponível em `https://st-it-cloud-public.s3.amazonaws.com/people-v2_1E6.csv.gz`\n",
        "\n",
        "### Data Quality\n",
        "\n",
        "- Higienizar e homogenizar o formato da coluna `document`\n",
        "- Detectar através da coluna `document` se o registro é de uma Pessoa Física ou Pessoa Jurídica, adicionando uma coluna com essa informação\n",
        "- Higienizar e homogenizar o formato da coluna `birthDate`\n",
        "- Existem duas colunas nesse dataset que em alguns registros estão trocadas. Quais são essas colunas? \n",
        "- Corrigir os dados com as colunas trocadas\n",
        "- Além desses pontos, existem outras tratamentos para homogenizar esse dataset. Aplique todos que conseguir.\n",
        "\n",
        "### Agregação dos dados\n",
        "\n",
        "- Quais são as 5 PF que mais gastaram (`totalSpent`)? \n",
        "- Qual é o valor de gasto médio por estado (`state`)?\n",
        "- Qual é o valor de gasto médio por `jobArea`?\n",
        "- Qual é a PF que gastou menos (`totalSpent`)?\n",
        "- Quantos nomes e documentos repetidos existem nesse dataset?\n",
        "- Quantas linhas existem nesse dataset?\n",
        "\n",
        "### Particionamento de dados tratados com as regras descritas em `DATA QUALITY`\n",
        "\n",
        "- Particionar em arquivos PARQUET por estado (`state`)\n",
        "- Particionar em arquivos CSV por ano/mes/dia de nascimento (`birthDate`)"
      ],
      "id": "a2da9c40"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2277f816"
      },
      "source": [
        ""
      ],
      "id": "2277f816",
      "execution_count": null,
      "outputs": []
    }
  ]
}